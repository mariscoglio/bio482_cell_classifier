{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook imports\n",
    "\n",
    "# Used to define paths to files for data import and export\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "# Basic libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "\n",
    "# Used for preprocessing and splitting of data \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Different models for feature selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Different models to be trained later, can be used as classifiers for feature selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection notebook\n",
    "\n",
    "### Part 1 : Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 : Splitting in train and test sets\n",
    "\n",
    "We need train and test sets to be able to do feature selection using the sklearn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 : Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical features\n",
    "categorical = []\n",
    "\n",
    "# Preprocess data\n",
    "# 1. Separate in categorical and continuous columns\n",
    "df_train_cat = df_train[df_train.columns[df_train.columns.isin(categorical)]]\n",
    "df_train_con = df_train[df_train.columns[~df_train.columns.isin(categorical)]]\n",
    "df_test_cat = df_test[df_test.columns[df_test.columns.isin(categorical)]]\n",
    "df_test_con = df_test[df_test.columns[~df_test.columns.isin(categorical)]]\n",
    "\n",
    "cols_cat = df_train_cat.columns\n",
    "cols_con = df_train_con.columns\n",
    "\n",
    "# 2. Fill the missing values if any, no missing values accepted by the models\n",
    "\n",
    "# For categorical variables\n",
    "imp_cat = SimpleImputer(strategy=\"most_frequent\")\n",
    "imp_cat = imp_cat.fit(df_train_cat)\n",
    "\n",
    "df_train_cat = imp_cat.transform(df_train_cat)\n",
    "df_test_cat = imp_cat.transform(df_test_cat)\n",
    "df_train_cat = pd.DataFrame(df_train_cat, columns=cols_cat)\n",
    "df_test_cat = pd.DataFrame(df_test_cat, columns=cols_cat)\n",
    "\n",
    "# For continuous variables\n",
    "imp_con = SimpleImputer(strategy=\"median\")\n",
    "imp_con = imp_con.fit(df_train_con)\n",
    "\n",
    "df_train_con = imp_con.transform(df_train_con)\n",
    "df_test_con = imp_con.transform(df_test_con)\n",
    "df_train_con = pd.DataFrame(df_train_con, columns=cols_con)\n",
    "df_test_con = pd.DataFrame(df_test_con, columns=cols_con)\n",
    "\n",
    "# 3. Scale the continuous variables\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df_train_con)\n",
    "\n",
    "df_train_con = scaler.transform(df_train_con)\n",
    "df_test_con = scaler.transform(df_test_con)\n",
    "df_train_con = pd.DataFrame(df_train_con, columns=cols_con)\n",
    "df_test_con = pd.DataFrame(df_test_con, columns=cols_con)\n",
    "\n",
    "# 4. Merge the categorical and continuous variables\n",
    "df_train = pd.concat([df_train_cat, df_train_con], axis=1)\n",
    "df_test = pd.concat([df_test_cat, df_test_con], axis=1)\n",
    "\n",
    "# 5. Get X and y matrices for feature classification\n",
    "X_train = df_train.drop(columns=[\"\"])\n",
    "y_train = df_train[\"\"]\n",
    "X_test = df_test.drop(columns=[\"\"])\n",
    "y_test = df_test[\"\"]\n",
    "\n",
    "# 6. Get feature names\n",
    "features = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 : Feature selection\n",
    "#### 4.1 Choosing classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the classifier\n",
    "classifier = LogisticRegression()\n",
    "name_classifier = 'LogisticRegression' # give the name of the classifier (str) to save the file at the end\n",
    "\n",
    "# Choosing the minimum number of features so consider\n",
    "min_features_to_select = 15 \n",
    "\n",
    "# List of other possible classifiers :\n",
    "    # LogisticRegression()\n",
    "    # KNeighborsClassifier()\n",
    "    # svm.SVC()\n",
    "    # MLPClassifier()\n",
    "    # QuadraticDiscriminantAnalysis()\n",
    "    # xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Recursive feature elimination (RFE) with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RFE object and compute a cross-validated score\n",
    "classifier = LogisticRegression(max_iter = 500)\n",
    "\n",
    "rfecv = RFECV(estimator=classifier,\n",
    "              step=1,\n",
    "              cv=StratifiedKFold(4),\n",
    "              scoring='f1',\n",
    "              min_features_to_select=min_features_to_select)\n",
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal number of features\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (f1_score)\")\n",
    "plt.plot(range(min_features_to_select, len(rfecv.grid_scores_) + min_features_to_select),\n",
    "         rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See feature ranking\n",
    "df_rfecv = pd.DataFrame(list(zip(features, rfecv.ranking_)), columns =['Feature', 'Rank']).sort_values(by='Rank')\n",
    "df_rfecv.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns selected\n",
    "features_rfecv = features[rfecv.support_]\n",
    "features_rfecv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Sequential Feature Selection\n",
    "##### 4.3.1 SelectFromModel\n",
    "\n",
    "First we get an idea of the importance of the features with a logistic regression. Features with the highest absolute coefficient are considered most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from coefficients\n",
    "classifier = LogisticRegression(max_iter = 500)\n",
    "importance_fit = classifier.fit(X_train, y_train)\n",
    "\n",
    "if len(importance_fit.coef_.tolist())>1:\n",
    "       importance = np.abs(importance_fit.coef_)  \n",
    "else:\n",
    "       importance = np.abs(importance_fit.coef_.tolist()[0])\n",
    "\n",
    "df_importance = pd.DataFrame(list(zip(features, importance)), columns =['Feature', 'Importance']).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(25, 7))\n",
    "plt.bar('Feature', 'Importance', data=df_importance)\n",
    "plt.title(\"Feature importances via coefficients\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See feature ranking\n",
    "df_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we select the features which are most important according to the coefficients using SelectFromModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.sort(importance)[-35] + 0.01\n",
    "sfm = SelectFromModel(classifier, threshold=threshold).fit(X_train, y_train)\n",
    "\n",
    "features_sfm = features[sfm.get_support()]\n",
    "print(f\"Features selected by SelectFromModel: {features_sfm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.2 SequentialFeatureSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward sequential feature selection\n",
    "classifier = LogisticRegression(max_iter = 500)\n",
    "sfs_forward = SequentialFeatureSelector(classifier, n_features_to_select=20, direction=\"forward\").fit(X_train, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backwards sequential feature selection, takes a lot of time to run\n",
    "classifier = LogisticRegression(max_iter = 500)\n",
    "sfs_backward = SequentialFeatureSelector(classifier, n_features_to_select=20, direction=\"backward\").fit(X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected features\n",
    "features_sfs_forward = features[sfs_forward.get_support()]\n",
    "print(\"Features selected by forward sequential selection:\\n \" f\"{features_sfs_forward}\")\n",
    "\n",
    "#print('------')\n",
    "\n",
    "features_sfs_backward = features[sfs_backward.get_support()]\n",
    "print(\"Features selected by backward sequential selection:\\n \" f\"{features_sfs_backward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio482",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
